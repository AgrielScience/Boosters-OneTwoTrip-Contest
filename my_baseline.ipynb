{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoncabanec/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "\n",
    "def calc_smooth_mean(df, by, on, weight):\n",
    "    mean = df[on].mean()\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "    smooth = (counts * means + weight * mean) / (counts + weight)\n",
    "    return df[by].map(smooth)\n",
    "\n",
    "def add_mte(merged_df, fields, weight, target):\n",
    "    df_train = merged_df[merged_df.type == 'train']\n",
    "    df_test = merged_df[merged_df.type == 'test']\n",
    "    for field in fields:\n",
    "        df_train[f'{field}_m'] = calc_smooth_mean(df_train, by=field, on=target, weight=weight)\n",
    "        df_test = pd.merge(df_test, df_train[[field, f'{field}_m']].drop_duplicates(), how='left', on=field)\n",
    "    return pd.concat([df_train, df_test], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (196056, 44)\n",
      "Shape of test data:  (455011, 38)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/onetwotrip_challenge_train.csv')\n",
    "df_train['type'] = 'train'\n",
    "df_test = pd.read_csv('data/onetwotrip_challenge_test.csv')\n",
    "df_test['type'] = 'test'\n",
    "print(\"Shape of train data: \", df_train.shape)\n",
    "print(\"Shape of test data: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651067, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(filter(lambda x: 'field' in x, df_train.columns))\n",
    "merged_df = pd.concat([df_train, df_test], axis=0, sort=False)\n",
    "main_features = ['field16', 'field1', 'field12', 'field25', 'field14', 'field22', 'field17', 'field13','field0', 'field8']\n",
    "grp_features = [x for x in features if x not in main_features]\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish  field16\n",
      "Finish  field1\n",
      "Finish  field12\n",
      "Finish  field25\n",
      "Finish  field14\n",
      "Finish  field22\n",
      "Finish  field17\n",
      "Finish  field13\n",
      "Finish  field0\n",
      "Finish  field8\n"
     ]
    }
   ],
   "source": [
    "for field in main_features:\n",
    "    for sub_field in grp_features:\n",
    "        sub_var_mean = merged_df.groupby([field])[sub_field].mean().reset_index().rename(\n",
    "            columns={sub_field: f\"mean_{field}_{sub_field}\"}).fillna(0)\n",
    "        sub_var_median = merged_df.groupby([field])[sub_field].median().reset_index().rename(\n",
    "            columns={sub_field: f\"med_{field}_{sub_field}\"}).fillna(0)\n",
    "        sub_var_std = merged_df.groupby([field])[sub_field].std().reset_index().rename(\n",
    "            columns={sub_field: f\"std_{field}_{sub_field}\"}).fillna(0)\n",
    "        merged_df = pd.merge(merged_df, sub_var_mean, how='left', on=field)\n",
    "        merged_df = pd.merge(merged_df, sub_var_median, how='left', on=field)\n",
    "        merged_df = pd.merge(merged_df, sub_var_std, how='left', on=field)\n",
    "    \n",
    "    print(\"Finish \", field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in features:\n",
    "    cnt=merged_df.groupby([field]).size().reset_index().rename(columns={0: f\"cnt_{field}\"})\n",
    "    merged_df = pd.merge(merged_df, cnt, how='left', on=field)\n",
    "    merged_df[f'log_{field}'] = np.log(merged_df[field]).replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df = add_mte(merged_df, features, weight=10, target='goal1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda x: 'field' in x, merged_df.columns))\n",
    "df_train = merged_df[merged_df.type==\"train\"]\n",
    "df_test = merged_df[merged_df.type==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['field10'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['goal1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=236)\n",
    "X = df_train[features]\n",
    "y = df_train['goal1']\n",
    "\n",
    "# Make importance dataframe\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "oof_preds = np.zeros(X.shape[0])\n",
    "getVal = np.zeros(X.shape[0])\n",
    "sub_preds = np.zeros(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "    \n",
    "    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    X_train, y_train = augment(X_train.values, y_train.values)\n",
    "    print(f\"Fold idx: {n_fold + 1}\")\n",
    "    trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        bagging_freq= 5,\n",
    "        bagging_fraction= 0.335,\n",
    "        #boost_from_average='false',\n",
    "        boost= 'gbdt',\n",
    "        feature_fraction= 0.041,\n",
    "        learning_rate= 0.01,\n",
    "        max_depth= -1,\n",
    "        metric='auc',\n",
    "        min_data_in_leaf= 80,\n",
    "        min_sum_hessian_in_leaf= 10.0,\n",
    "        num_leaves= 13,\n",
    "        num_threads= 8,\n",
    "        tree_learner= 'serial',\n",
    "        objective= 'binary', \n",
    "        verbosity= -1,\n",
    "        n_estimators=10000,\n",
    "        scale_pos_weight = 10,\n",
    "        random_state=432013\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        verbose=1000,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X.iloc[val_idx])[:, 1]\n",
    "    getVal[val_idx]+= model.predict_proba(X.iloc[val_idx])[:, 1] / kfolds.n_splits\n",
    "\n",
    "    sub_preds += model.predict_proba(df_test[features])[:, 1] / kfolds.n_splits\n",
    "    \n",
    "print(\"ROC_AUC score: \", roc_auc_score(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold idx: 1\n",
      "0:\ttest: 0.6530477\ttest1: 0.6536841\tbest: 0.6536841 (0)\ttotal: 125ms\tremaining: 2h 4m 44s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6905496708\n",
      "bestIteration = 224\n",
      "\n",
      "Shrink model to first 225 iterations.\n",
      "Fold idx: 2\n",
      "0:\ttest: 0.6541396\ttest1: 0.6490752\tbest: 0.6490752 (0)\ttotal: 64.4ms\tremaining: 1h 4m 22s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6778209793\n",
      "bestIteration = 329\n",
      "\n",
      "Shrink model to first 330 iterations.\n",
      "Fold idx: 3\n",
      "0:\ttest: 0.6556792\ttest1: 0.6476543\tbest: 0.6476543 (0)\ttotal: 63.9ms\tremaining: 1h 3m 56s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6867937312\n",
      "bestIteration = 286\n",
      "\n",
      "Shrink model to first 287 iterations.\n",
      "Fold idx: 4\n",
      "0:\ttest: 0.6506984\ttest1: 0.6623750\tbest: 0.6623750 (0)\ttotal: 83.1ms\tremaining: 1h 23m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6954769419\n",
      "bestIteration = 244\n",
      "\n",
      "Shrink model to first 245 iterations.\n",
      "Fold idx: 5\n",
      "0:\ttest: 0.6565102\ttest1: 0.6435902\tbest: 0.6435902 (0)\ttotal: 61.1ms\tremaining: 1h 1m 5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6830824537\n",
      "bestIteration = 202\n",
      "\n",
      "Shrink model to first 203 iterations.\n",
      "ROC_AUC score:  0.6862827872683985\n"
     ]
    }
   ],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    #X_train, y_train = augment(X_train.values, y_train.values)\n",
    "\n",
    "    print(f\"Fold idx: {n_fold + 1}\")\n",
    "    \n",
    "    model = cb.CatBoostClassifier(\n",
    "        #allow_writing_files = False,\n",
    "        #od_type = 'Iter',\n",
    "        bagging_temperature = 0.2,\n",
    "        #depth = 5,\n",
    "        od_wait = 20,\n",
    "        #silent = False,\n",
    "        #verbose = 50\n",
    "        scale_pos_weight = 44,\n",
    "        subsample = 0.36, \n",
    "        custom_loss='Logloss',\n",
    "        random_strength = 0,\n",
    "        max_depth=3,\n",
    "        eval_metric=\"AUC\",\n",
    "        learning_rate=0.03,\n",
    "        iterations=60000,\n",
    "        #bootstrap_type='Bernoulli',\n",
    "        l2_leaf_reg=0.3,\n",
    "        random_seed=432013,\n",
    "        od_type=\"Iter\",\n",
    "        border_count=128\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        verbose=1500,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    \n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = features\n",
    "    imp_df['gain'] = model.feature_importances_\n",
    "    imp_df['fold'] = n_fold + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_valid)[:, 1]\n",
    "    test_preds = model.predict_proba(df_test[features])[:, 1]\n",
    "    sub_preds += test_preds / kfolds.n_splits\n",
    "    \n",
    "print(\"ROC_AUC score: \", roc_auc_score(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances['gain_log'] = importances['gain']\n",
    "mean_gain = importances[['gain', 'feature']].groupby('feature').mean()\n",
    "importances['mean_gain'] = importances['feature'].map(mean_gain['gain'])\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "sns.barplot(x='gain_log', y='feature', data=importances.sort_values('mean_gain', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime. now()\n",
    "pd.DataFrame(sub_preds, columns=['proba'], \n",
    "             index=df_test['orderid']).to_csv(f'sub-{str(now)[:19]}-{round(roc_auc_score(y, oof_preds),4)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
